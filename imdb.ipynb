{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb # new!\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # new!\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import Embedding # new!\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint # new!\n",
    "import os # new!\n",
    "from sklearn.metrics import roc_auc_score, roc_curve # new!\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # new!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters for Dense Layer Architecture\n",
    "Setting up hyperparameters upfront is a good practice to enable experimentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/dense'\n",
    "\n",
    "# training:\n",
    "epochs = 4 \n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding:\n",
    "n_dim = 64 # The number of dinemsions in our word vector space\n",
    "n_unique_words = 5000 # Sort words based on the number of times they arrear and take top 5000\n",
    "n_words_to_skip = 50 #Skip 50 most frequently appearing words as \n",
    "max_review_length = 100 #Truncate reviews longer that 100 words (pad shorter)\n",
    "pad_type = trunc_type = 'pre' #Add padding at the begining \n",
    "\n",
    "# neural network architecture:\n",
    "n_dense = 64 # Neuron in the dense layers\n",
    "dropout = 0.5 # Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words, skip_top=n_words_to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([list([2, 2, 2, 2, 2, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 2, 173, 2, 256, 2, 2, 100, 2, 838, 112, 50, 670, 2, 2, 2, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 2, 2, 172, 4536, 1111, 2, 546, 2, 2, 447, 2, 192, 50, 2, 2, 147, 2025, 2, 2, 2, 2, 1920, 4613, 469, 2, 2, 71, 87, 2, 2, 2, 530, 2, 76, 2, 2, 1247, 2, 2, 2, 515, 2, 2, 2, 626, 2, 2, 2, 62, 386, 2, 2, 316, 2, 106, 2, 2, 2223, 2, 2, 480, 66, 3785, 2, 2, 130, 2, 2, 2, 619, 2, 2, 124, 51, 2, 135, 2, 2, 1415, 2, 2, 2, 2, 215, 2, 77, 52, 2, 2, 407, 2, 82, 2, 2, 2, 107, 117, 2, 2, 256, 2, 2, 2, 3766, 2, 723, 2, 71, 2, 530, 476, 2, 400, 317, 2, 2, 2, 2, 1029, 2, 104, 88, 2, 381, 2, 297, 98, 2, 2071, 56, 2, 141, 2, 194, 2, 2, 2, 226, 2, 2, 134, 476, 2, 480, 2, 144, 2, 2, 2, 51, 2, 2, 224, 92, 2, 104, 2, 226, 65, 2, 2, 1334, 88, 2, 2, 283, 2, 2, 4472, 113, 103, 2, 2, 2, 2, 2, 178, 2]),\n",
       "       list([2, 194, 1153, 194, 2, 78, 228, 2, 2, 1463, 4369, 2, 134, 2, 2, 715, 2, 118, 1634, 2, 394, 2, 2, 119, 954, 189, 102, 2, 207, 110, 3103, 2, 2, 69, 188, 2, 2, 2, 2, 2, 249, 126, 93, 2, 114, 2, 2300, 1523, 2, 647, 2, 116, 2, 2, 2, 2, 229, 2, 340, 1322, 2, 118, 2, 2, 130, 4901, 2, 2, 1002, 2, 89, 2, 952, 2, 2, 2, 455, 2, 2, 2, 2, 1543, 1905, 398, 2, 1649, 2, 2, 2, 163, 2, 3215, 2, 2, 1153, 2, 194, 775, 2, 2, 2, 349, 2637, 148, 605, 2, 2, 2, 123, 125, 68, 2, 2, 2, 349, 165, 4362, 98, 2, 2, 228, 2, 2, 2, 1157, 2, 299, 120, 2, 120, 174, 2, 220, 175, 136, 50, 2, 4373, 228, 2, 2, 2, 656, 245, 2350, 2, 2, 2, 131, 152, 491, 2, 2, 2, 2, 1212, 2, 2, 2, 371, 78, 2, 625, 64, 1382, 2, 2, 168, 145, 2, 2, 1690, 2, 2, 2, 1355, 2, 2, 2, 52, 154, 462, 2, 89, 78, 285, 2, 145, 95]),\n",
       "       list([2, 2, 2, 2, 2, 2, 2, 2, 249, 108, 2, 2, 2, 54, 61, 369, 2, 71, 149, 2, 2, 112, 2, 2401, 311, 2, 2, 3711, 2, 75, 2, 1829, 296, 2, 86, 320, 2, 534, 2, 263, 4821, 1301, 2, 1873, 2, 89, 78, 2, 66, 2, 2, 360, 2, 2, 58, 316, 334, 2, 2, 1716, 2, 645, 662, 2, 257, 85, 1200, 2, 1228, 2578, 83, 68, 3912, 2, 2, 165, 1539, 278, 2, 69, 2, 780, 2, 106, 2, 2, 1338, 2, 2, 2, 2, 215, 2, 610, 2, 2, 87, 326, 2, 2300, 2, 2, 2, 2, 272, 2, 57, 2, 2, 2, 2, 2, 2, 2307, 51, 2, 170, 2, 595, 116, 595, 1352, 2, 191, 79, 638, 89, 2, 2, 2, 2, 106, 607, 624, 2, 534, 2, 227, 2, 129, 113])],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "x_train[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Strings\n",
    "The dataset is convinently stored as word vectors \n",
    "\n",
    "Checking the string reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"PAD\"] = 0\n",
    "word_index[\"START\"] = 1\n",
    "word_index[\"UNK\"] = 2\n",
    "index_word = {v:k for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"UNK UNK UNK UNK UNK brilliant casting location scenery story direction everyone's really suited UNK part UNK played UNK UNK could UNK imagine being there robert UNK UNK UNK amazing actor UNK now UNK same being director UNK father came UNK UNK same scottish island UNK myself UNK UNK loved UNK fact there UNK UNK real connection UNK UNK UNK UNK witty remarks throughout UNK UNK were great UNK UNK UNK brilliant UNK much UNK UNK bought UNK UNK UNK soon UNK UNK UNK released UNK UNK UNK would recommend UNK UNK everyone UNK watch UNK UNK fly UNK UNK amazing really cried UNK UNK end UNK UNK UNK sad UNK UNK know what UNK say UNK UNK cry UNK UNK UNK UNK must UNK been good UNK UNK definitely UNK also UNK UNK UNK two little UNK UNK played UNK UNK UNK norman UNK paul UNK were UNK brilliant children UNK often left UNK UNK UNK UNK list UNK think because UNK stars UNK play them UNK grown up UNK such UNK big UNK UNK UNK whole UNK UNK these children UNK amazing UNK should UNK UNK UNK what UNK UNK done don't UNK think UNK whole story UNK UNK lovely because UNK UNK true UNK UNK someone's life after UNK UNK UNK UNK UNK us UNK\""
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "Padding to standardize the lenght of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  52,  835, 1120,  542, 2603,    2, 1408,    2,    2, 2364,    2,\n",
       "          2,    2,  276,    2,    2, 3239,    2,  129, 1642,    2,  607,\n",
       "          2,    2,  852,    2,    2,    2,  605,  852, 3925,    2, 2777,\n",
       "          2,  852,    2,    2, 2146,    2,  608, 4044,    2,    2,    2,\n",
       "        789,    2,    2,    2,   54, 1544, 2173, 2018,    2,   79,   72,\n",
       "        202,   72,    2,  968,    2,    2,    2, 2872,   75,  359, 2872,\n",
       "          2,    2,    2,    2,   75,    2,    2,    2,    2,    2,    2,\n",
       "        884, 1866,    2,    2, 4017, 2809,    2,    2,  719,    2,   70,\n",
       "       2885,    2, 2552,    2, 4430,  175,    2,    2,    2,    2,  543,\n",
       "       1609], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "x_train[14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words,n_dim,input_length=max_review_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_dense,activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 100, 64)           320000    \n_________________________________________________________________\nflatten (Flatten)            (None, 6400)              0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                409664    \n_________________________________________________________________\ndropout (Dropout)            (None, 64)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 729,729\nTrainable params: 729,729\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 27s 137ms/step - loss: 0.1082 - accuracy: 0.9635 - val_loss: 0.4698 - val_accuracy: 0.8384\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 27s 138ms/step - loss: 0.0629 - accuracy: 0.9801 - val_loss: 0.5514 - val_accuracy: 0.8348\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 26s 135ms/step - loss: 0.0431 - accuracy: 0.9865 - val_loss: 0.6592 - val_accuracy: 0.8324\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 27s 136ms/step - loss: 0.0285 - accuracy: 0.9900 - val_loss: 0.7170 - val_accuracy: 0.8329\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e70e754f0>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# training\n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'all_x_valid' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9faacd728e10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_x_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_x_valid' is not defined"
     ]
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in all_x_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 388.0125 248.518125\" width=\"388.0125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-11-28T10:36:18.850017</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 388.0125 248.518125 \nL 388.0125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 46.0125 224.64 \nL 380.8125 224.64 \nL 380.8125 7.2 \nL 46.0125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 61.230682 224.64 \nL 91.667049 224.64 \nL 91.667049 17.554286 \nL 61.230682 17.554286 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 91.667047 224.64 \nL 122.103415 224.64 \nL 122.103415 207.564367 \nL 91.667047 207.564367 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 122.103406 224.64 \nL 152.539777 224.64 \nL 152.539777 212.434313 \nL 122.103406 212.434313 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 152.539777 224.64 \nL 182.976139 224.64 \nL 182.976139 214.139821 \nL 152.539777 214.139821 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 182.97613 224.64 \nL 213.412491 224.64 \nL 213.412491 215.228881 \nL 182.97613 215.228881 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 213.412501 224.64 \nL 243.848871 224.64 \nL 243.848871 215.249429 \nL 213.412501 215.249429 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 243.848871 224.64 \nL 274.285224 224.64 \nL 274.285224 213.934338 \nL 243.848871 213.934338 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 274.285224 224.64 \nL 304.721595 224.64 \nL 304.721595 212.22883 \nL 274.285224 212.22883 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 304.721613 224.64 \nL 335.157966 224.64 \nL 335.157966 205.488989 \nL 304.721613 205.488989 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 335.157947 224.64 \nL 365.594318 224.64 \nL 365.594318 18.869377 \nL 335.157947 18.869377 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m3ed4998cac\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"61.230683\" xlink:href=\"#m3ed4998cac\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g transform=\"translate(53.27912 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"122.10341\" xlink:href=\"#m3ed4998cac\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g transform=\"translate(114.151847 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"182.976137\" xlink:href=\"#m3ed4998cac\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g transform=\"translate(175.024575 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"243.848864\" xlink:href=\"#m3ed4998cac\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g transform=\"translate(235.897302 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"304.721591\" xlink:href=\"#m3ed4998cac\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g transform=\"translate(296.770029 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"365.594318\" xlink:href=\"#m3ed4998cac\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g transform=\"translate(357.642756 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m854ecc80b8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m854ecc80b8\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(32.65 228.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m854ecc80b8\" y=\"183.543411\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2000 -->\n      <g transform=\"translate(13.5625 187.342629)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m854ecc80b8\" y=\"142.446821\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 4000 -->\n      <g transform=\"translate(13.5625 146.24604)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m854ecc80b8\" y=\"101.350232\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 6000 -->\n      <g transform=\"translate(13.5625 105.14945)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m854ecc80b8\" y=\"60.253642\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 8000 -->\n      <g transform=\"translate(13.5625 64.052861)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.0125\" xlink:href=\"#m854ecc80b8\" y=\"19.157053\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 10000 -->\n      <g transform=\"translate(7.2 22.956271)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#pc4b2893e13)\" d=\"M 213.412501 224.64 \nL 213.412501 7.2 \n\" style=\"fill:none;stroke:#ffa500;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 46.0125 224.64 \nL 46.0125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 380.8125 224.64 \nL 380.8125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 46.0125 224.64 \nL 380.8125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 46.0125 7.2 \nL 380.8125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc4b2893e13\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"46.0125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'91.57'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# looking at the AUC\n",
    "pct_auc= roc_auc_score(y_valid,y_hat)*100.0\n",
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network\n",
    "CNNs are good at detecting spatial patterns. We can use it here here to detect spatial patterns between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import SpatialDropout1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding:\n",
    "n_dim = 64 # The number of dinemsions in our word vector space\n",
    "n_unique_words = 5000 # Sort words based on the number of times they arrear and take top 5000\n",
    "max_review_length = 400 #Truncate reviews longer that 100 words (pad shorter)\n",
    "pad_type = trunc_type = 'pre' #Add padding at the begining \n",
    "drop_embed = 0.2\n",
    "\n",
    "# convolutional architecture\n",
    "n_conv = 256 # filters a.k.a kernels\n",
    "k_conv = 3 #Kernel length\n",
    "\n",
    "# desnse layer architecture\n",
    "n_dense = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo padding due the change in max review length\n",
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# vector-space embedding\n",
    "model.add(Embedding(n_unique_words,n_dim,\n",
    "            input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "\n",
    "#convolutional layer\n",
    "model.add(Conv1D(n_conv, k_conv, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# Global max-pooling is common for dimensionality reduction within deep learning NLP models\n",
    "# We use it here to squash the activation map from 398 × 256 to 1 × 256.\n",
    "\n",
    "#dense layer\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 400, 64)           320000    \n_________________________________________________________________\nspatial_dropout1d_1 (Spatial (None, 400, 64)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 398, 256)          49408     \n_________________________________________________________________\nglobal_max_pooling1d_1 (Glob (None, 256)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 256)               65792     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 435,457\nTrainable params: 435,457\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 27s 135ms/step - loss: 0.5175 - accuracy: 0.7292 - val_loss: 0.3752 - val_accuracy: 0.8292\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 26s 135ms/step - loss: 0.3216 - accuracy: 0.8637 - val_loss: 0.3460 - val_accuracy: 0.8468\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 26s 135ms/step - loss: 0.2374 - accuracy: 0.9044 - val_loss: 0.3582 - val_accuracy: 0.8476\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 26s 135ms/step - loss: 0.1660 - accuracy: 0.9373 - val_loss: 0.4026 - val_accuracy: 0.8416\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e319b2250>"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "# training\n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(25000, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "RNNs can handle longer sequences rather than just looking at 3 words like with the above CNN filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters for RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training \n",
    "epochs = 16 # need more \n",
    "batch_size = 128\n",
    "\n",
    "# vector space embedding\n",
    "n_dim = 64\n",
    "n_unique_words = 10000\n",
    "max_review_length = 100 # lowered due to vanishing gradient over time\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2\n",
    "\n",
    "# RNN layer architecture\n",
    "\n",
    "n_rnn = 256\n",
    "drop_rnn = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words,\n",
    "                    n_dim, input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(SimpleRNN(n_rnn, dropout=drop_rnn))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo padding due the change in max review length\n",
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/16\n",
      "196/196 [==============================] - 17s 88ms/step - loss: 0.6938 - accuracy: 0.5256 - val_loss: 0.6946 - val_accuracy: 0.5137\n",
      "Epoch 2/16\n",
      "196/196 [==============================] - 18s 90ms/step - loss: 0.6411 - accuracy: 0.6126 - val_loss: 0.6918 - val_accuracy: 0.5624\n",
      "Epoch 3/16\n",
      "196/196 [==============================] - 17s 89ms/step - loss: 0.5998 - accuracy: 0.6622 - val_loss: 0.5535 - val_accuracy: 0.7166\n",
      "Epoch 4/16\n",
      "196/196 [==============================] - 17s 89ms/step - loss: 0.5808 - accuracy: 0.6917 - val_loss: 0.6278 - val_accuracy: 0.6330\n",
      "Epoch 5/16\n",
      "196/196 [==============================] - 18s 90ms/step - loss: 0.5492 - accuracy: 0.7148 - val_loss: 0.4817 - val_accuracy: 0.7763\n",
      "Epoch 6/16\n",
      "196/196 [==============================] - 20s 103ms/step - loss: 0.5913 - accuracy: 0.6736 - val_loss: 0.6198 - val_accuracy: 0.6404\n",
      "Epoch 7/16\n",
      "196/196 [==============================] - 22s 111ms/step - loss: 0.5449 - accuracy: 0.7134 - val_loss: 0.5730 - val_accuracy: 0.7058\n",
      "Epoch 8/16\n",
      "196/196 [==============================] - 20s 102ms/step - loss: 0.4972 - accuracy: 0.7623 - val_loss: 0.5913 - val_accuracy: 0.7127\n",
      "Epoch 9/16\n",
      "196/196 [==============================] - 19s 97ms/step - loss: 0.5078 - accuracy: 0.7547 - val_loss: 0.6319 - val_accuracy: 0.6313\n",
      "Epoch 10/16\n",
      "196/196 [==============================] - 19s 97ms/step - loss: 0.5029 - accuracy: 0.7537 - val_loss: 0.5137 - val_accuracy: 0.7622\n",
      "Epoch 11/16\n",
      "196/196 [==============================] - 19s 99ms/step - loss: 0.4649 - accuracy: 0.7880 - val_loss: 0.5075 - val_accuracy: 0.7691\n",
      "Epoch 12/16\n",
      "196/196 [==============================] - 19s 97ms/step - loss: 0.4355 - accuracy: 0.8085 - val_loss: 0.5202 - val_accuracy: 0.7480\n",
      "Epoch 13/16\n",
      "196/196 [==============================] - 19s 95ms/step - loss: 0.4123 - accuracy: 0.8220 - val_loss: 0.5246 - val_accuracy: 0.7732\n",
      "Epoch 14/16\n",
      "196/196 [==============================] - 19s 97ms/step - loss: 0.3849 - accuracy: 0.8364 - val_loss: 0.4787 - val_accuracy: 0.7908\n",
      "Epoch 15/16\n",
      "196/196 [==============================] - 19s 95ms/step - loss: 0.3854 - accuracy: 0.8350 - val_loss: 0.5159 - val_accuracy: 0.7847\n",
      "Epoch 16/16\n",
      "196/196 [==============================] - 19s 96ms/step - loss: 0.4625 - accuracy: 0.7880 - val_loss: 0.4909 - val_accuracy: 0.7795\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e6215de50>"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "# training\n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not good because the only place a Simple RNN architecture would perform well is if we have 10 or less consecutive timestamps of information relevant to our problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "epochs = 4\n",
    "batch_size =128\n",
    "\n",
    "# vector space embedding\n",
    "n_dim = 64\n",
    "n_unique_words = 10000\n",
    "max_review_length = 100\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2\n",
    "\n",
    "#LSTM architecture\n",
    "n_lstm = 256\n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim,\n",
    "                    input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(LSTM(n_lstm, dropout=drop_lstm))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_5 (Embedding)      (None, 100, 64)           640000    \n_________________________________________________________________\nspatial_dropout1d_4 (Spatial (None, 100, 64)           0         \n_________________________________________________________________\nlstm (LSTM)                  (None, 256)               328704    \n_________________________________________________________________\ndense_7 (Dense)              (None, 1)                 257       \n=================================================================\nTotal params: 968,961\nTrainable params: 968,961\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo padding due the change in max review length\n",
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 70s 359ms/step - loss: 0.5251 - accuracy: 0.7227 - val_loss: 0.3543 - val_accuracy: 0.8457\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 79s 403ms/step - loss: 0.3286 - accuracy: 0.8609 - val_loss: 0.3572 - val_accuracy: 0.8423\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 79s 403ms/step - loss: 0.2825 - accuracy: 0.8846 - val_loss: 0.3510 - val_accuracy: 0.8457\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 76s 390ms/step - loss: 0.2584 - accuracy: 0.8973 - val_loss: 0.3757 - val_accuracy: 0.8386\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e63492a30>"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "# training\n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi Directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim,\n",
    "                    input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Bidirectional(LSTM(n_lstm, dropout=drop_lstm)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_7 (Embedding)      (None, 100, 64)           640000    \n_________________________________________________________________\nspatial_dropout1d_6 (Spatial (None, 100, 64)           0         \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 512)               657408    \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 1,297,921\nTrainable params: 1,297,921\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 111s 564ms/step - loss: 0.5733 - accuracy: 0.6764 - val_loss: 0.3718 - val_accuracy: 0.8372\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 111s 568ms/step - loss: 0.3369 - accuracy: 0.8573 - val_loss: 0.3493 - val_accuracy: 0.8472\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 105s 535ms/step - loss: 0.2864 - accuracy: 0.8841 - val_loss: 0.3862 - val_accuracy: 0.8428\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 103s 526ms/step - loss: 0.2617 - accuracy: 0.8946 - val_loss: 0.3555 - val_accuracy: 0.8488\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8dc08e2370>"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "# training\n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters for stacked RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked architecture\n",
    "n_lstm_1 = 256 # neurons on the first RNN\n",
    "n_lstm_2 = 512 # neurons on the second RNN\n",
    "drop_lstm = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_unique_words, n_dim,\n",
    "                    input_length=max_review_length))\n",
    "model.add(SpatialDropout1D(drop_embed))\n",
    "model.add(Bidirectional(LSTM(n_lstm_1, dropout=drop_lstm,\n",
    "                             return_sequences=True))) # new!\n",
    "model.add(Bidirectional(LSTM(n_lstm_2, dropout=drop_lstm)))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_10\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_9 (Embedding)      (None, 100, 64)           640000    \n_________________________________________________________________\nspatial_dropout1d_8 (Spatial (None, 100, 64)           0         \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, 100, 512)          657408    \n_________________________________________________________________\nbidirectional_3 (Bidirection (None, 1024)              4198400   \n_________________________________________________________________\ndense_10 (Dense)             (None, 1)                 1025      \n=================================================================\nTotal params: 5,496,833\nTrainable params: 5,496,833\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 675s 3s/step - loss: 0.5432 - accuracy: 0.7076 - val_loss: 0.3770 - val_accuracy: 0.8310\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 657s 3s/step - loss: 0.3257 - accuracy: 0.8614 - val_loss: 0.3478 - val_accuracy: 0.8458\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 655s 3s/step - loss: 0.2771 - accuracy: 0.8884 - val_loss: 0.3937 - val_accuracy: 0.8270\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 673s 3s/step - loss: 0.2456 - accuracy: 0.9030 - val_loss: 0.3819 - val_accuracy: 0.8396\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e71a0df70>"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "# training\n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-ConvNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters for Multi-ConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training:\n",
    "epochs = 4\n",
    "batch_size = 128\n",
    "\n",
    "# vector-space embedding:\n",
    "n_dim = 64\n",
    "n_unique_words = 5000\n",
    "max_review_length = 400\n",
    "pad_type = trunc_type = 'pre'\n",
    "drop_embed = 0.2\n",
    "\n",
    "# convolutional layer architecture:\n",
    "n_conv_1 = n_conv_2 = n_conv_3 = 256\n",
    "k_conv_1 = 2\n",
    "k_conv_2 = 3\n",
    "k_conv_3 = 4\n",
    "\n",
    "# dense layer architecture:\n",
    "n_dense = 256\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo padding due the change in max review length\n",
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate\n",
    "\n",
    "#Input layer\n",
    "input_layer = Input(shape=(max_review_length,), dtype='int16', name='input')\n",
    "\n",
    "# embedding\n",
    "embedding_layer = Embedding(n_unique_words, n_dim,\n",
    "                            name='embedding')(input_layer)\n",
    "drop_embed_layer = SpatialDropout1D(drop_embed,\n",
    "                                    name='drop_embed')(embedding_layer)\n",
    "\n",
    "# three convolutional layers\n",
    "conv_1 = Conv1D(n_conv_1, k_conv_1,\n",
    "                activation='relu',name='conv_1d')(drop_embed_layer)\n",
    "maxp_1 = GlobalMaxPooling1D(name='maxp_1')(conv_1)\n",
    "\n",
    "conv_2 = Conv1D(n_conv_2,k_conv_2, activation='relu', name='conv_2')(drop_embed_layer)\n",
    "maxp_2 = GlobalMaxPooling1D(name='maxp_2')(conv_2)\n",
    "\n",
    "conv_3 = Conv1D(n_conv_3,k_conv_3,activation='relu', name='conv_3')(drop_embed_layer)\n",
    "maxp_3 = GlobalMaxPooling1D(name='maxp_3')(conv_3)\n",
    "\n",
    "# Concatenate the activations from the three layers\n",
    "\n",
    "concat = concatenate([maxp_1,maxp_2,maxp_3])\n",
    "\n",
    "# dense hidden layer\n",
    "dense_layer = Dense(n_dense, activation='relu', name='dense')(concat)\n",
    "drop_dense_layer = Dropout(dropout, name='drop_dense')(dense_layer)\n",
    "\n",
    "dense_2 = Dense(int(n_dense/4), activation='relu', name='dense_2')(drop_dense_layer)\n",
    "dropout_2 = Dropout(dropout, name='drop_dense_2')(dense_2)\n",
    "\n",
    "# sigmoid output layer\n",
    "predictions = Dense(1, activation='sigmoid', name='output')(dropout_2)\n",
    "\n",
    "# create model\n",
    "model = Model(input_layer, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput (InputLayer)              [(None, 400)]        0                                            \n__________________________________________________________________________________________________\nembedding (Embedding)           (None, 400, 64)      320000      input[0][0]                      \n__________________________________________________________________________________________________\ndrop_embed (SpatialDropout1D)   (None, 400, 64)      0           embedding[0][0]                  \n__________________________________________________________________________________________________\nconv_1d (Conv1D)                (None, 399, 256)     33024       drop_embed[0][0]                 \n__________________________________________________________________________________________________\nconv_2 (Conv1D)                 (None, 398, 256)     49408       drop_embed[0][0]                 \n__________________________________________________________________________________________________\nconv_3 (Conv1D)                 (None, 397, 256)     65792       drop_embed[0][0]                 \n__________________________________________________________________________________________________\nmaxp_1 (GlobalMaxPooling1D)     (None, 256)          0           conv_1d[0][0]                    \n__________________________________________________________________________________________________\nmaxp_2 (GlobalMaxPooling1D)     (None, 256)          0           conv_2[0][0]                     \n__________________________________________________________________________________________________\nmaxp_3 (GlobalMaxPooling1D)     (None, 256)          0           conv_3[0][0]                     \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 768)          0           maxp_1[0][0]                     \n                                                                 maxp_2[0][0]                     \n                                                                 maxp_3[0][0]                     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 256)          196864      concatenate_2[0][0]              \n__________________________________________________________________________________________________\ndrop_dense (Dropout)            (None, 256)          0           dense[0][0]                      \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 64)           16448       drop_dense[0][0]                 \n__________________________________________________________________________________________________\ndrop_dense_2 (Dropout)          (None, 64)           0           dense_2[0][0]                    \n__________________________________________________________________________________________________\noutput (Dense)                  (None, 1)            65          drop_dense_2[0][0]               \n==================================================================================================\nTotal params: 681,601\nTrainable params: 681,601\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/4\n",
      "196/196 [==============================] - 68s 344ms/step - loss: 0.5152 - accuracy: 0.7167 - val_loss: 0.3659 - val_accuracy: 0.8376\n",
      "Epoch 2/4\n",
      "196/196 [==============================] - 67s 344ms/step - loss: 0.3258 - accuracy: 0.8630 - val_loss: 0.3487 - val_accuracy: 0.8461\n",
      "Epoch 3/4\n",
      "196/196 [==============================] - 68s 346ms/step - loss: 0.2500 - accuracy: 0.9017 - val_loss: 0.3525 - val_accuracy: 0.8444\n",
      "Epoch 4/4\n",
      "196/196 [==============================] - 69s 350ms/step - loss: 0.1740 - accuracy: 0.9360 - val_loss: 0.4150 - val_accuracy: 0.8392\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8df00c5220>"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "# training\n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "         validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}